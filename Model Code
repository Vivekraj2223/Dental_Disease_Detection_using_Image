# Verify all libraries are imported
import os
import numpy as np
import pandas as pd
from tqdm import tqdm
import random
from collections import Counter
import cv2
from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, models
from torch.utils.data import Dataset, DataLoader, random_split
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split

# Specific imports for MobileNetV2 and ResNet50 only
from torchvision.models import mobilenet_v2, resnet50
from torchvision.models import MobileNet_V2_Weights, ResNet50_Weights
from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau

print("‚úÖ All libraries imported successfully!")
print(f"PyTorch version: {torch.__version__}")

# Check GPU availability
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üöÄ Using device: {device}")

if torch.cuda.is_available():
    print(f"üéÆ GPU: {torch.cuda.get_device_name(0)}")
    print(f"üíæ Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# Set random seeds for reproducibility
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)
print("üéØ Random seeds set for reproducibility")

# Display available models
print("\nü§ñ Available Models:")
print("   - MobileNetV2")
print("   - ResNet50")

import kagglehub
path = kagglehub.dataset_download("salmansajid05/oral-diseases")

import os
from pathlib import Path

# Simple path discovery
def discover_dataset_structure(base_path):
    base_path = Path(base_path)
    print("üîç Discovering dataset structure...")

    all_images = {}

    # Recursively find all image files
    for root, dirs, files in os.walk(base_path):
        root_path = Path(root)
        image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.JPG'))]

        if image_files:
            category_name = root_path.relative_to(base_path)
            all_images[str(category_name)] = {
                'path': root_path,
                'image_count': len(image_files),
                'sample_files': image_files[:3]  # First 3 files
            }
            print(f"‚úÖ {category_name}: {len(image_files)} images")

    return all_images

# Discover the actual structure
dataset_path = "/kaggle/input/oral-diseases"
dataset_structure = discover_dataset_structure(dataset_path)

print(f"\nüìä Total categories found: {len(dataset_structure)}")
for category, info in dataset_structure.items():
    print(f"   {category}: {info['image_count']} images")

import os
from pathlib import Path

class DatasetPaths:
    def __init__(self, base_path):
        self.base_path = Path(base_path)

        # Define paths based on ACTUAL discovered structure
        self.calculus = self.base_path / "Calculus" / "Calculus"
        self.caries_original = self.base_path / "Data caries" / "Data caries" / "caries orignal data set" / "done"
        self.caries_augmented = self.base_path / "Data caries" / "Data caries" / "caries augmented data set" / "preview"
        self.gingivitis = self.base_path / "Gingivitis" / "Gingivitis"
        self.mouth_ulcer_original = self.base_path / "Mouth Ulcer" / "Mouth Ulcer" / "ulcer original dataset" / "ulcer original dataset"
        self.mouth_ulcer_augmented = self.base_path / "Mouth Ulcer" / "Mouth Ulcer" / "Mouth_Ulcer_augmented_DataSet" / "preview"
        self.tooth_discoloration_original = self.base_path / "Tooth Discoloration" / "Tooth Discoloration " / "tooth discoloration original dataset" / "tooth discoloration original dataset"
        self.tooth_discoloration_augmented = self.base_path / "Tooth Discoloration" / "Tooth Discoloration " / "Tooth_discoloration_augmented_dataser" / "preview"
        self.hypodontia = self.base_path / "hypodontia" / "hypodontia"

        # YOLO dataset paths
        self.yolo_images_train = self.base_path / "Caries_Gingivitus_ToothDiscoloration_Ulcer-yolo_annotated-Dataset" / "Caries_Gingivitus_ToothDiscoloration_Ulcer-yolo_annotated-Dataset" / "Data" / "images" / "train"
        self.yolo_images_val = self.base_path / "Caries_Gingivitus_ToothDiscoloration_Ulcer-yolo_annotated-Dataset" / "Caries_Gingivitus_ToothDiscoloration_Ulcer-yolo_annotated-Dataset" / "Data" / "images" / "val"

    def verify_paths(self):
        """Verify all paths exist"""
        paths = {
            "Calculus": self.calculus,
            "Caries Original": self.caries_original,
            "Caries Augmented": self.caries_augmented,
            "Gingivitis": self.gingivitis,
            "Mouth Ulcer Original": self.mouth_ulcer_original,
            "Mouth Ulcer Augmented": self.mouth_ulcer_augmented,
            "Tooth Discoloration Original": self.tooth_discoloration_original,
            "Tooth Discoloration Augmented": self.tooth_discoloration_augmented,
            "Hypodontia": self.hypodontia,
            "YOLO Train Images": self.yolo_images_train,
            "YOLO Val Images": self.yolo_images_val
        }

        available_paths = {}

        for name, path in paths.items():
            if path.exists():
                images = list(path.glob("*.jpg")) + list(path.glob("*.JPG")) + list(path.glob("*.png")) + list(path.glob("*.jpeg"))
                print(f"‚úÖ {name}: {len(images)} images")
                available_paths[name] = path
            else:
                print(f"‚ùå {name}: Path not found - {path}")

        return available_paths

# Initialize paths
dataset_path = "/kaggle/input/oral-diseases"
paths = DatasetPaths(dataset_path)
available_paths = paths.verify_paths()

def collect_dataset(paths):
    """Collect all ORIGINAL images and their labels (avoid augmented data for training)"""
    data = []

    # Define class mappings for 6 main classes
    class_mappings = {
        'calculus': 0,
        'caries': 1,
        'gingivitis': 2,
        'mouth_ulcer': 3,
        'tooth_discoloration': 4,
        'hypodontia': 5
    }

    # Use only ORIGINAL datasets for training to avoid data leakage
    categories = {
        'calculus': paths.calculus,
        'caries': paths.caries_original,  # Original caries data
        'gingivitis': paths.gingivitis,
        'mouth_ulcer': paths.mouth_ulcer_original,  # Original mouth ulcer data
        'tooth_discoloration': paths.tooth_discoloration_original,  # Original tooth discoloration
        'hypodontia': paths.hypodontia
    }

    print("üìÇ Collecting ORIGINAL images from all classes...")

    for class_name, class_path in categories.items():
        if class_path and class_path.exists():
            # Get all image files
            image_files = (list(class_path.glob("*.jpg")) +
                          list(class_path.glob("*.JPG")) +
                          list(class_path.glob("*.png")) +
                          list(class_path.glob("*.jpeg")))

            for img_path in image_files:
                data.append({
                    'image_path': str(img_path),
                    'label': class_mappings[class_name],
                    'class_name': class_name
                })

            print(f"‚úÖ {class_name}: {len(image_files)} ORIGINAL images")
        else:
            print(f"‚ùå {class_name}: Original path not available")

    return data, list(class_mappings.keys())

# Collect all ORIGINAL data
dataset, class_names = collect_dataset(paths)
print(f"\nüìä Total ORIGINAL dataset size: {len(dataset)} images")
print(f"üè∑Ô∏è All Classes: {class_names}")

# Create DataFrame
df = pd.DataFrame(dataset)
print(f"\nüìã Class Distribution (Original Data):")
print(df['class_name'].value_counts())

def split_dataset(df, test_size=0.15, val_size=0.15, random_state=42):
    """Split dataset into train, validation and test sets with stratification"""

    # Check if we have enough samples for stratification
    min_samples = df.groupby('label').size().min()
    if min_samples < 2:
        print("‚ö†Ô∏è Warning: Some classes have very few samples, using random split")
        train_val_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)
        train_df, val_df = train_test_split(train_val_df, test_size=val_size/(1-test_size), random_state=random_state)
    else:
        # First split: separate test set with stratification
        train_val_df, test_df = train_test_split(
            df,
            test_size=test_size,
            stratify=df['label'],
            random_state=random_state
        )

        # Second split: separate validation from train with stratification
        train_df, val_df = train_test_split(
            train_val_df,
            test_size=val_size/(1-test_size),
            stratify=train_val_df['label'],
            random_state=random_state
        )

    print(f"üöÄ Dataset Split Complete:")
    print(f"   üü¢ Training set: {len(train_df)} images ({len(train_df)/len(df)*100:.1f}%)")
    print(f"   üü° Validation set: {len(val_df)} images ({len(val_df)/len(df)*100:.1f}%)")
    print(f"   üî¥ Test set: {len(test_df)} images ({len(test_df)/len(df)*100:.1f}%)")

    return train_df, val_df, test_df

# Perform the split
train_df, val_df, test_df = split_dataset(df)

# Display detailed class distribution
print("\nüìä Detailed Class Distribution:")
print("üü¢ Training Set:")
print(train_df['class_name'].value_counts().sort_index())
print("\nüü° Validation Set:")
print(val_df['class_name'].value_counts().sort_index())
print("\nüî¥ Test Set:")
print(test_df['class_name'].value_counts().sort_index())

class OralDiseaseDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        """
        Custom Dataset for Oral Diseases
        Args:
            dataframe: DataFrame with image paths and labels
            transform: Image transformations/augmentations
        """
        self.dataframe = dataframe.reset_index(drop=True)
        self.transform = transform
        self.classes = sorted(dataframe['class_name'].unique())
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        img_path = self.dataframe.loc[idx, 'image_path']
        label = self.dataframe.loc[idx, 'label']
        class_name = self.dataframe.loc[idx, 'class_name']

        # Load image
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"Error loading image {img_path}: {e}")
            # Return a black image as fallback
            image = Image.new('RGB', (224, 224), color='black')

        # Apply transformations
        if self.transform:
            image = self.transform(image)

        return image, label, class_name

# Define transforms
def get_transforms():
    """Get training and validation transforms"""

    # Training transforms with augmentation
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # Validation transforms (no augmentation)
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    return train_transform, val_transform

# Create transforms
train_transform, val_transform = get_transforms()

# Create datasets
train_dataset = OralDiseaseDataset(train_df, transform=train_transform)
val_dataset = OralDiseaseDataset(val_df, transform=val_transform)
test_dataset = OralDiseaseDataset(test_df, transform=val_transform)

print("‚úÖ Datasets created successfully!")
print(f"üü¢ Training samples: {len(train_dataset)}")
print(f"üü° Validation samples: {len(val_dataset)}")
print(f"üî¥ Test samples: {len(test_dataset)}")
print(f"üè∑Ô∏è Classes: {train_dataset.classes}")

# Create data loaders
batch_size = 32

train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=2,
    pin_memory=True if torch.cuda.is_available() else False
)

val_loader = DataLoader(
    val_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=2,
    pin_memory=True if torch.cuda.is_available() else False
)

test_loader = DataLoader(
    test_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=2,
    pin_memory=True if torch.cuda.is_available() else False
)

print("‚úÖ DataLoaders created successfully!")
print(f"üì¶ Batch size: {batch_size}")
print(f"üü¢ Training batches: {len(train_loader)}")
print(f"üü° Validation batches: {len(val_loader)}")
print(f"üî¥ Test batches: {len(test_loader)}")

# Test one batch
print("\nüß™ Testing one batch...")
for images, labels, class_names in train_loader:
    print(f"Image batch shape: {images.shape}")
    print(f"Labels batch shape: {labels.shape}")
    print(f"Sample labels: {labels[:5]}")
    print(f"Sample class names: {class_names[:5]}")
    break

def visualize_batch_samples(dataloader, class_names, num_images=8):
    """Visualize sample images from a DataLoader batch"""

    # Get one batch
    for images, labels, batch_class_names in dataloader:
        break

    # Denormalize for visualization
    def denormalize(tensor):
        mean = torch.tensor([0.485, 0.456, 0.406]).view(-1, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(-1, 1, 1)
        tensor = tensor * std + mean
        tensor = torch.clamp(tensor, 0, 1)
        return tensor

    # Plot images
    fig, axes = plt.subplots(2, 4, figsize=(15, 8))
    axes = axes.ravel()

    for i in range(min(num_images, len(images))):
        img = denormalize(images[i]).permute(1, 2, 0).numpy()
        label = labels[i].item()
        class_name = batch_class_names[i]

        axes[i].imshow(img)
        axes[i].set_title(f'{class_name}\n(Lab: {label})', fontsize=10)
        axes[i].axis('off')

    # Hide empty subplots
    for i in range(len(images), len(axes)):
        axes[i].axis('off')

    plt.tight_layout()
    plt.show()

    return images, labels

print("üñºÔ∏è Sample images from Training DataLoader (after transformations):")
train_images, train_labels = visualize_batch_samples(train_loader, class_names)

print("üñºÔ∏è Sample images from Validation DataLoader:")
val_images, val_labels = visualize_batch_samples(val_loader, class_names)

def plot_class_distribution(train_df, val_df, test_df, class_names):
    """Plot class distribution across splits"""

    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    # Training distribution
    train_counts = [len(train_df[train_df['class_name'] == cls]) for cls in class_names]
    axes[0].bar(class_names, train_counts, color='green', alpha=0.7)
    axes[0].set_title('üü¢ Training Set Distribution', fontsize=14, fontweight='bold')
    axes[0].set_ylabel('Number of Images')
    axes[0].tick_params(axis='x', rotation=45)

    # Add count labels on bars
    for i, v in enumerate(train_counts):
        axes[0].text(i, v + 10, str(v), ha='center', va='bottom')

    # Validation distribution
    val_counts = [len(val_df[val_df['class_name'] == cls]) for cls in class_names]
    axes[1].bar(class_names, val_counts, color='orange', alpha=0.7)
    axes[1].set_title('üü° Validation Set Distribution', fontsize=14, fontweight='bold')
    axes[1].set_ylabel('Number of Images')
    axes[1].tick_params(axis='x', rotation=45)

    for i, v in enumerate(val_counts):
        axes[1].text(i, v + 5, str(v), ha='center', va='bottom')

    # Test distribution
    test_counts = [len(test_df[test_df['class_name'] == cls]) for cls in class_names]
    axes[2].bar(class_names, test_counts, color='red', alpha=0.7)
    axes[2].set_title('üî¥ Test Set Distribution', fontsize=14, fontweight='bold')
    axes[2].set_ylabel('Number of Images')
    axes[2].tick_params(axis='x', rotation=45)

    for i, v in enumerate(test_counts):
        axes[2].text(i, v + 5, str(v), ha='center', va='bottom')

    plt.tight_layout()
    plt.show()

    # Print summary
    print("üìä CLASS DISTRIBUTION SUMMARY:")
    print("="*50)
    for cls in class_names:
        train_count = len(train_df[train_df['class_name'] == cls])
        val_count = len(val_df[val_df['class_name'] == cls])
        test_count = len(test_df[test_df['class_name'] == cls])
        total = train_count + val_count + test_count
        print(f"{cls:20} | Train: {train_count:4d} | Val: {val_count:3d} | Test: {test_count:3d} | Total: {total:4d}")

# Plot class distribution
plot_class_distribution(train_df, val_df, test_df, class_names)

# Enhanced transforms with strong augmentation
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader # Ensure Dataset and DataLoader are imported
from PIL import Image # Ensure Image is imported
from sklearn.model_selection import train_test_split # Needed for split_dataset
import pandas as pd # Needed for split_dataset (df)
import os # Required for DatasetPaths and collect_dataset
from pathlib import Path # Required for DatasetPaths and collect_dataset

# OralDiseaseDataset class definition (copied for self-containment in this cell)
class OralDiseaseDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        """
        Custom Dataset for Oral Diseases
        Args:
            dataframe: DataFrame with image paths and labels
            transform: Image transformations/augmentations
        """
        self.dataframe = dataframe.reset_index(drop=True)
        self.transform = transform
        self.classes = sorted(dataframe['class_name'].unique())
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        img_path = self.dataframe.loc[idx, 'image_path']
        label = self.dataframe.loc[idx, 'label']
        class_name = self.dataframe.loc[idx, 'class_name']

        # Load image
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"Error loading image {img_path}: {e}")
            # Return a black image as fallback
            image = Image.new('RGB', (224, 224), color='black')

        # Apply transformations
        if self.transform:
            image = self.transform(image)

        return image, label, class_name

# DatasetPaths class definition (copied for self-containment)
class DatasetPaths:
    def __init__(self, base_path):
        self.base_path = Path(base_path)

        # Define paths based on ACTUAL discovered structure
        self.calculus = self.base_path / "Calculus" / "Calculus"
        self.caries_original = self.base_path / "Data caries" / "Data caries" / "caries orignal data set" / "done"
        self.caries_augmented = self.base_path / "Data caries" / "Data caries" / "caries augmented data set" / "preview"
        self.gingivitis = self.base_path / "Gingivitis" / "Gingivitis"
        self.mouth_ulcer_original = self.base_path / "Mouth Ulcer" / "Mouth Ulcer" / "ulcer original dataset" / "ulcer original dataset"
        self.mouth_ulcer_augmented = self.base_path / "Mouth Ulcer" / "Mouth Ulcer" / "Mouth_Ulcer_augmented_DataSet" / "preview"
        self.tooth_discoloration_original = self.base_path / "Tooth Discoloration" / "Tooth Discoloration " / "tooth discoloration original dataset" / "tooth discoloration original dataset"
        self.tooth_discoloration_augmented = self.base_path / "Tooth Discoloration" / "Tooth Discoloration " / "Tooth_discoloration_augmented_dataser" / "preview"
        self.hypodontia = self.base_path / "hypodontia" / "hypodontia"

        # YOLO dataset paths
        self.yolo_images_train = self.base_path / "Caries_Gingivitus_ToothDiscoloration_Ulcer-yolo_annotated-Dataset" / "Caries_Gingivitus_ToothDiscoloration_Ulcer-yolo_annotated-Dataset" / "Data" / "images" / "train"
        self.yolo_images_val = self.base_path / "Caries_Gingivitus_ToothDiscoloration_Ulcer-yolo_annotated-Dataset" / "Caries_Gingivitus_ToothDiscoloration_Ulcer-yolo_annotated-Dataset" / "Data" / "images" / "val"

    def verify_paths(self):
        """Verify all paths exist"""
        # This method is not strictly needed for `df` generation but part of the class, so keeping it as a stub
        pass

# Collect dataset function (copied for self-containment)
def collect_dataset(paths):
    """Collect all ORIGINAL images and their labels (avoid augmented data for training)"""
    data = []

    # Define class mappings for 6 main classes
    class_mappings = {
        'calculus': 0,
        'caries': 1,
        'gingivitis': 2,
        'mouth_ulcer': 3,
        'tooth_discoloration': 4,
        'hypodontia': 5
    }

    # Use only ORIGINAL datasets for training to avoid data leakage
    categories = {
        'calculus': paths.calculus,
        'caries': paths.caries_original,  # Original caries data
        'gingivitis': paths.gingivitis,
        'mouth_ulcer': paths.mouth_ulcer_original,  # Original mouth ulcer data
        'tooth_discoloration': paths.tooth_discoloration_original,  # Original tooth discoloration
        'hypodontia': paths.hypodontia
    }

    for class_name, class_path in categories.items():
        if class_path and class_path.exists():
            # Get all image files
            image_files = (list(class_path.glob("*.jpg")) +
                          list(class_path.glob("*.JPG")) +
                          list(class_path.glob("*.png")) +
                          list(class_path.glob("*.jpeg")))

            for img_path in image_files:
                data.append({
                    'image_path': str(img_path),
                    'label': class_mappings[class_name],
                    'class_name': class_name
                })
        else:
            pass # Suppress prints from this copied function

    return data, list(class_mappings.keys())


# Re-create df within this cell to ensure it's defined
dataset_path = "/kaggle/input/oral-diseases"
paths = DatasetPaths(dataset_path)
dataset, class_names = collect_dataset(paths)
df = pd.DataFrame(dataset)


def split_dataset(df, test_size=0.15, val_size=0.15, random_state=42):
    """Split dataset into train, validation and test sets with stratification"""

    # Check if we have enough samples for stratification
    min_samples = df.groupby('label').size().min()
    if min_samples < 2:
        print("‚ö†Ô∏è Warning: Some classes have very few samples, using random split")
        train_val_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)
        train_df, val_df = train_test_split(train_val_df, test_size=val_size/(1-test_size), random_state=random_state)
    else:
        # First split: separate test set with stratification
        train_val_df, test_df = train_test_split(
            df,
            test_size=test_size,
            stratify=df['label'],
            random_state=random_state
        )

        # Second split: separate validation from train with stratification
        train_df, val_df = train_test_split(
            train_val_df,
            test_size=val_size/(1-test_size),
            stratify=train_val_df['label'],
            random_state=random_state
        )

    print(f"üöÄ Dataset Split Complete:")
    print(f"   üü¢ Training set: {len(train_df)} images ({len(train_df)/len(df)*100:.1f}%)")
    print(f"   üü° Validation set: {len(val_df)} images ({len(val_df)/len(df)*100:.1f}%)")
    print(f"   üî¥ Test set: {len(test_df)} images ({len(test_df)/len(df)*100:.1f}%)")

    return train_df, val_df, test_df

# NOTE: This cell now also defines train_df, val_df, test_df for robustness
train_df, val_df, test_df = split_dataset(df) # Assumes 'df' is defined in an earlier cell

def get_enhanced_transforms():
    """Get enhanced training transforms with strong augmentation"""

    # Strong training transforms
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomCrop((224, 224)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomVerticalFlip(p=0.3),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),
        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # Validation transforms
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    return train_transform, val_transform

# Create enhanced datasets
train_transform, val_transform = get_enhanced_transforms()

train_dataset = OralDiseaseDataset(train_df, transform=train_transform)
val_dataset = OralDiseaseDataset(val_df, transform=val_transform)
test_dataset = OralDiseaseDataset(test_df, transform=val_transform)

# Increased batch size for better performance
batch_size = 64

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)

print("‚úÖ Enhanced datasets and loaders created!")
print(f"üì¶ Batch size: {batch_size}")

import torch.nn as nn
from torchvision.models import mobilenet_v2
from torchvision.models import MobileNet_V2_Weights
import torch # Ensure torch is imported for device definition

# Check GPU availability (repeated for self-containment)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class EnhancedMobileNetV2(nn.Module):
    def __init__(self, num_classes=6, dropout_rate=0.3):
        super(EnhancedMobileNetV2, self).__init__()

        # Load pretrained MobileNetV2
        self.backbone = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)

        # Freeze early layers (optional - you can experiment)
        # for param in list(self.backbone.parameters())[:-20]:
        #     param.requires_grad = False

        # Get the number of features in the classifier
        in_features = self.backbone.classifier[1].in_features

        # Enhanced classifier with multiple dense layers
        self.backbone.classifier = nn.Sequential(
            nn.Dropout(p=dropout_rate),
            nn.Linear(in_features, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(inplace=True),

            nn.Dropout(p=dropout_rate),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),

            nn.Dropout(p=dropout_rate),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),

            nn.Dropout(p=dropout_rate),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        return self.backbone(x)

# Create model
model = EnhancedMobileNetV2(num_classes=len(class_names))
model = model.to(device)

print("üöÄ Enhanced MobileNetV2 Model Created!")
print(f"üìç Number of classes: {len(class_names)}")
print(f"‚ö° Device: {device}")

# Model summary
def model_summary(model):
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print("üìä MODEL SUMMARY:")
    print("="*50)
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    print(f"Non-trainable parameters: {total_params - trainable_params:,}")
    print("="*50)

    # Layer-wise summary
    for name, module in model.named_children():
        num_params = sum(p.numel() for p in module.parameters())
        print(f"{name:20} | Parameters: {num_params:>10,}")

model_summary(model)

# Callbacks and training utilities
class ModelCheckpoint:
    def __init__(self, filepath, monitor='val_accuracy', mode='max', save_best_only=True):
        self.filepath = filepath
        self.monitor = monitor
        self.mode = mode
        self.save_best_only = save_best_only
        self.best_value = -float('inf') if mode == 'max' else float('inf')

    def __call__(self, value, model, optimizer, epoch):
        if self.mode == 'max':
            condition = value > self.best_value
        else:
            condition = value < self.best_value

        if condition:
            self.best_value = value
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_value': self.best_value,
                'class_names': class_names
            }
            torch.save(checkpoint, self.filepath)
            print(f"üéØ Checkpoint saved! {self.monitor} = {value:.4f}")

class EarlyStopping:
    def __init__(self, patience=10, monitor='val_loss', mode='min'):
        self.patience = patience
        self.monitor = monitor
        self.mode = mode
        self.counter = 0
        self.best_value = -float('inf') if mode == 'max' else float('inf')
        self.early_stop = False

    def __call__(self, current_value):
        if self.mode == 'max':
            condition = current_value > self.best_value
        else:
            condition = current_value < self.best_value

        if condition:
            self.best_value = current_value
            self.counter = 0
            print(f"‚úÖ EarlyStopping: Improved {self.monitor} to {current_value:.4f}")
        else:
            self.counter += 1
            print(f"‚ö†Ô∏è EarlyStopping: No improvement for {self.counter}/{self.patience} epochs")
            if self.counter >= self.patience:
                self.early_stop = True
                print("üõë EarlyStopping: Training stopped")

# Initialize callbacks
checkpoint_callback = ModelCheckpoint(
    filepath='best_mobilenetv2_oral_disease.pth',
    monitor='val_accuracy',
    mode='max'
)

early_stopping = EarlyStopping(
    patience=15,
    monitor='val_accuracy',
    mode='max'
)

import os
print(os.listdir("/content"))


# TRAINING CODE

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from torchvision.models import mobilenet_v2, MobileNet_V2_Weights
from sklearn.utils.class_weight import compute_class_weight
import numpy as np
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# MODEL

class EnhancedMobileNetV2(nn.Module):
    def __init__(self, num_classes=6):
        super().__init__()
        self.backbone = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)
        in_features = self.backbone.classifier[1].in_features
        self.backbone.classifier = nn.Sequential(
            nn.Dropout(0.4),
            nn.Linear(in_features, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(1024, num_classes)
        )

    def forward(self, x):
        return self.backbone(x)

model = EnhancedMobileNetV2(num_classes=len(class_names)).to(device)


# FREEZE BACKBONE

for param in model.backbone.features.parameters():
    param.requires_grad = False

# TRANSFORMS

train_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(
        brightness=0.4,
        contrast=0.4,
        saturation=0.3,
        hue=0.05
    ),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# DATASETS & LOADERS

train_dataset = OralDiseaseDataset(train_df, transform=train_transform)
val_dataset   = OralDiseaseDataset(val_df, transform=val_transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)

# CLASS WEIGHTS (NORMALIZED)

labels = train_df["label"].values
class_weights = compute_class_weight(
    class_weight="balanced",
    classes=np.unique(labels),
    y=labels
)
class_weights = class_weights / class_weights.sum()
class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)

# LOSS + OPTIMIZER

criterion = nn.CrossEntropyLoss(
    weight=class_weights,
    label_smoothing=0.1
)

optimizer = optim.AdamW(
    model.parameters(),
    lr=1e-4,
    weight_decay=1e-4
)

# LR SCHEDULER (LOSS REDUCTION)

scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='max',
    factor=0.5,
    patience=2,
)

# TRAINING LOOP

best_val_acc = 0

for epoch in range(10):
    model.train()
    total_loss = 0

    for images, labels, _ in tqdm(train_loader, desc=f"Epoch {epoch+1}/10"):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    # -------- VALIDATION --------
    model.eval()
    correct, total = 0, 0

    with torch.no_grad():
        for images, labels, _ in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    val_acc = correct / total
    print(f"Epoch {epoch+1} | Loss: {total_loss:.2f} | Val Acc: {val_acc:.4f}")

    scheduler.step(val_acc)

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), "best_mobilenetv2_oral_disease_FIXED.pth")
        print("‚úÖ Model saved")

print("üéØ Training complete")

